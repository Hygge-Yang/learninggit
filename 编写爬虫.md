# 编写爬虫

网络爬虫是一种程序，它的主要目的是将互联网上的网页下载到本地并提取出相关数据。网络爬虫可以自动化地浏览网络中的信息，然后根据我们制定的规则下载和提取信息。

网页下载器是爬虫的核心部分之一，下载网页就需要实现HTTP请求（下载网页，解析网页）

+ 实现HTTP请求需要用到包

1.Urllib库

2.Requests库

+ HTTP请求信息

请求方法

1.GET方法

   请求指定的方面信息，并返回实体主体

2.POST方法

   向指定资源提交数据进行处理请求（例如提交表单或者上传文件），数据被包含在请求体中。

+ 请求头部

+ 请求正文

网页解析器也是爬虫的核心部分之一。主要用于从HTML网页信息中提取我们需要的、有价值的数据和链接。

+ Requests库的安装

   pip install requests

404 客户端错误

502 服务端错误

301 重定向

200 正常相应

+ 常用网页解析工具

​       LXML

​       Beautifulsoup

​       正则表达式